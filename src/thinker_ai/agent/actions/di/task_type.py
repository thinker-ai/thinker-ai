# Prompt for taking on "eda" tasks
import os
from thinker_ai.common.common import replace_curly_braces

PLAN_PROMPT = """
    Based on the instruction, write a plan or modify an existing plan of what you should do to achieve the goal.
    If you are modifying an existing plan, carefully follow the instruction, don't make unnecessary changes. Give the whole plan unless instructed to modify only one task of the plan.
    If you encounter errors on the current task, revise and output the current single task only.
    Output a list of jsons following the format:
    ```json
    [
        {{
            "parent_id" = "the parent id"
            "id": str = "unique identifier for a task in plan,format is 'parent_id.id', the id at the end can be an ordinal number",
            "dependent_task_ids": list[str] = "ids of tasks prerequisite to this task",
            "instruction": "what you should do in this task, one short phrase or sentence",
            "type": "type of this task, should be one of Available Task Types",
        }},
        ...
    ]
    ```
    Please note the following:
    -The tasks in the plan is according to the Single Level of Abstraction (SLOA) principle，each subtask should remain at the same level of abstraction. 
    -Do not further decompose the subtasks into more detailed steps. Provide a single level of subtasks only.
"""


def load_file(base_dir: str, file_name: str) -> str:
    file_path = os.path.join(base_dir, file_name)
    if os.path.exists(file_path):
        with open(file_path, 'r') as file:
            return file.read()
    return ""


current_file_dir = os.path.dirname(__file__)
status_machine_dir = os.path.dirname(os.path.join(current_file_dir, "../../../status_machine/"))
status_definition_simple = replace_curly_braces(load_file(status_machine_dir, "status_definition_example.json"))
status_definition_schema_simple = replace_curly_braces(load_file(status_machine_dir, "status_definition_schema.json"))
STATE_FLOW_PROMPT = """
Based on the instruction, design a state machine from scratch, or update an existing state machine, you have to 
decompose the state according to the instruction, each decomposition only generates a state machine,  each of which,
 should be able to be mapped to an Available Task Type, if it can not be mapped, it means that there is a coarse 
 strength of the state, the state is expressed as the name of the sub-state machine, for the next decomposition 
 Preparing for sub-state machines!
 Output json following the format:
    ```json
{status_definition_simple}
    ```
    The json schema is:
    ```json
{status_definition_schema_simple}
    ```
    Please note the following:
    -The state_defs in the flow is according to the Single Level of Abstraction (SLOA) principle，each state_def should remain at the same level of abstraction. 
    -A state_def allows multiple Actions to be configured, each Action corresponds to a command, each Action generates an event, and the next state generated by each event is determined in transitions.
    -The state flow has at least one 'end state' witch has only four properties:id、name、description、state_context_class_name
    -The key of the generated json root is the id of the state machine.
    -Generate only one state machine at a time based on the prompt
    -If you want to generate a child state machine based on the state of a parent state machine, make sure that the key of the child state machine itself matches the state_def id of the parent state machine.
    -If a state machine is not a child state machine,the inner_end_state_to_outer_event attribute should not exist, otherwise use it to map the end state of the child state machine to a legitimate event in the current state of the parent state machine.
    -When reprogramming the exist status definition associated with the exist status instance, you have to look carefully at the current and historical states, and can only modify the state of state_def_id that is not in the current and historical states,and don't make unnecessary changes. 
""".format(status_definition_simple=status_definition_simple,
           status_definition_schema_simple=status_definition_schema_simple)

EDA_PROMPT = """
        The current task is about exploratory data analysis, please note the following:
        - Distinguish column types with `select_dtypes` for tailored analysis and visualization, such as correlation.
        - Remember to `import numpy as np` before using Numpy functions.
"""

# Prompt for taking on "data_preprocess" tasks
DATA_PREPROCESS_PROMPT = """
        The current task is about data preprocessing, please note the following:
        - Monitor data types per column, applying appropriate methods.
        - Ensure operations are on existing dataset columns.
        - Avoid writing processed data to files.
        - Avoid any change to label column, such as standardization, etc.
        - Prefer alternatives to one-hot encoding for categorical data.
        - Only encode or scale necessary columns to allow for potential feature-specific engineering tasks (like time_extract, binning, extraction, etc.) later.
        - Each step do data preprocessing to train, must do same for test separately at the same time.
        - Always copy the DataFrame before processing it and use the copy to process.
"""

# Prompt for taking on "feature_engineering" tasks
FEATURE_ENGINEERING_PROMPT = """
        The current task is about feature engineering. when performing it, please adhere to the following principles:
        - Generate as diverse features as possible to improve the model's performance step-by-step. 
        - Use available feature engineering tools if they are potential impactful.
        - Avoid creating redundant or excessively numerous features in one step.
        - Exclude ID columns from feature generation and remove them.
        - Each feature engineering operation performed on the train set must also applies to the test separately at the same time.
        - Avoid using the label column to create features, except for cat encoding.
        - Use the data from previous task result if exist, do not mock or reload data yourself.
        - Always copy the DataFrame before processing it and use the copy to process.
"""

# Prompt for taking on "model_train" tasks
MODEL_TRAIN_PROMPT = """
        The current task is about training a model, please ensure high performance:
        - Keep in mind that your user prioritizes results and is highly focused on model performance. So, when needed, feel free to use models of any complexity to improve effectiveness, such as XGBoost, CatBoost, etc.
        - If non-numeric columns exist, perform label encode together with all steps.
        - Use the data from previous task result directly, do not mock or reload data yourself.
        - Set suitable hyperparameters for the model, make metrics as high as possible.
"""

# Prompt for taking on "model_evaluate" tasks
MODEL_EVALUATE_PROMPT = """
        The current task is about evaluating a model, please note the following:
        - Ensure that the evaluated data is same processed as the training data. If not, remember use object in 'Done Tasks' to transform the data.
        - Use trained model from previous task result directly, do not mock or reload model yourself.
"""

# Prompt for taking on "image2webpage" tasks
IMAGE2WEBPAGE_PROMPT = """
        The current task is about converting image into webpage code. please note the following:
        - Single-Step Code Generation: Execute the entire code generation process in a single step, encompassing HTML, CSS, and JavaScript. Avoid fragmenting the code generation into multiple separate steps to maintain consistency and simplify the development workflow.
        - Save webpages: Be sure to use the save method provided.
"""
